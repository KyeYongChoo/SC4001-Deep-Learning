{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d15a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python standard library\n",
    "import contextlib\n",
    "import io\n",
    "import os\n",
    "import threading\n",
    "import warnings\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "from safetensors.torch import load_file as safe_load\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*_MultiProcessingDataLoaderIter.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b97562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_head(model, model_name):\n",
    "\tif \"vit\" in model_name:\n",
    "\t\tfor name, param in model.named_parameters():\n",
    "\t\t\tif name.startswith(\"head\"):  # ViT classifier head\n",
    "\t\t\t\tparam.requires_grad = True\n",
    "\t\t\telse:\n",
    "\t\t\t\tparam.requires_grad = False\n",
    "\telif \"resnet\" in model_name:\n",
    "\t\tfor name, param in model.named_parameters():\n",
    "\t\t\tif \"fc\" in name:  # 'fc' is the final classifier for resnets\n",
    "\t\t\t\tparam.requires_grad = False\n",
    "\t\t\telse:\n",
    "\t\t\t\tparam.requires_grad = False\n",
    "\telse:\n",
    "\t\traise NotImplementedError(\n",
    "\t\t\tf\"Freeze head received unknown model type {model_name}\"\n",
    "\t\t)\n",
    "\treturn model\n",
    "\n",
    "def load_masked_state_dict(state_dict, model, verbose = False):\n",
    "\t# --- 1. Clean state_dict if it contains mask-based weights ---\n",
    "\tcleaned_state = {}\n",
    "\tfor k, v in state_dict.items():\n",
    "\t\tif k.endswith(\".weight_orig\"):\n",
    "\t\t\tbase = k[:-len(\".weight_orig\")]\n",
    "\t\t\tmask_key = base + \".weight_mask\"\n",
    "\t\t\tif mask_key in state_dict:\n",
    "\t\t\t\tcleaned_state[base + \".weight\"] = (\n",
    "\t\t\t\t\tstate_dict[k] * state_dict[mask_key]\n",
    "\t\t\t\t)\n",
    "\t\t\telse:\n",
    "\t\t\t\tcleaned_state[base + \".weight\"] = v\n",
    "\t\telif k.endswith(\".weight_mask\"):\n",
    "\t\t\tcontinue  # skip mask tensors themselves\n",
    "\t\telse:\n",
    "\t\t\tcleaned_state[k] = v\n",
    "\n",
    "\t# --- 2. Drop classification head weights (fc/head/classifier) ---\n",
    "\tfor bad_key in [\"fc.weight\", \"fc.bias\", \"head.weight\", \"head.bias\", \"classifier.weight\", \"classifier.bias\"]:\n",
    "\t\tcleaned_state.pop(bad_key, None)\n",
    "\n",
    "\t# --- 3. Load silently (suppress size mismatch noise) ---\n",
    "\twith contextlib.redirect_stderr(io.StringIO()):\n",
    "\t\tmissing, unexpected = model.load_state_dict(cleaned_state, strict=False)\n",
    "\n",
    "\t# --- 4. Optional logging if you want visibility ---\n",
    "\tif verbose:\n",
    "\t\tignored = [k for k in missing if any(x in k for x in [\"fc\", \"head\", \"classifier\"])]\n",
    "\t\tif ignored:\n",
    "\t\t\tprint(f\"Ignored classification head weights: {ignored}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Model state restored successfully.\")\n",
    "\n",
    "\treturn model, missing, unexpected\n",
    "\n",
    "\n",
    "def create_model_with_timeout(\n",
    "\tmodel_name: str,\n",
    "\tnum_classes: int,\n",
    "\tdevice: torch.device,\n",
    "\ttimeout: int = 10,\n",
    "\tverbose: bool = False,\n",
    "):\n",
    "\t\"\"\"Create a TIMM model safely with timeout, local weight loading, and pruning mask support.\"\"\"\n",
    "\tresult = {}\n",
    "\n",
    "\tdef target():\n",
    "\t\ttry:\n",
    "\t\t\tmodel = timm.create_model(model_name, pretrained=False, num_classes=num_classes)\n",
    "\n",
    "\t\t\t# --- Find local weight file ---\n",
    "\t\t\tweights_dir = \"../original_weights\"\n",
    "\t\t\tweight_path = None\n",
    "\t\t\tfor ext in (\".safetensors\", \".pth\", \".pt\"):\n",
    "\t\t\t\tpath = os.path.join(weights_dir, f\"{model_name}{ext}\")\n",
    "\t\t\t\tif os.path.exists(path):\n",
    "\t\t\t\t\tweight_path = path\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\tif weight_path is None:\n",
    "\t\t\t\traise FileNotFoundError(f\"No local weights found for {model_name} in {weights_dir}\")\n",
    "\n",
    "\t\t\t# --- Load weights (supporting masks) ---\n",
    "\t\t\ttry:\n",
    "\t\t\t\tstate_dict = (\n",
    "\t\t\t\t\tsafe_load(weight_path)\n",
    "\t\t\t\t\tif weight_path.endswith(\".safetensors\")\n",
    "\t\t\t\t\telse torch.load(weight_path, map_location=\"cpu\")\n",
    "\t\t\t\t)\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\traise RuntimeError(f\"Failed to load {weight_path}: {e}\")\n",
    "\n",
    "\t\t\tmodel, missing, unexpected = load_masked_state_dict(state_dict, model, verbose)\n",
    "\n",
    "\t\t\tresult[\"model\"] = model.to(device)\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tresult[\"error\"] = str(e)\n",
    "\n",
    "\t# --- Run model creation in a separate thread with timeout ---\n",
    "\tthread = threading.Thread(target=target, daemon=True)\n",
    "\tthread.start()\n",
    "\tthread.join(timeout)\n",
    "\n",
    "\tif thread.is_alive():\n",
    "\t\traise TimeoutError(f\"Creating model '{model_name}' timed out after {timeout}s.\")\n",
    "\n",
    "\t# --- Fallback path ---\n",
    "\tif \"error\" in result:\n",
    "\t\tprint(f\"Local load failed: {result['error']}\")\n",
    "\t\tprint(\"Retrying with pretrained=True via TIMM ...\")\n",
    "\t\tmodel = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "\t\tresult[\"model\"] = model.to(device)\n",
    "\n",
    "\t# --- Optional cleanup ---\n",
    "\tif \"model\" not in result:\n",
    "\t\traise RuntimeError(f\"Model creation failed for '{model_name}'.\")\n",
    "\n",
    "\treturn result[\"model\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f7847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model Setup ===\n",
    "\n",
    "# Default list for full experiments\n",
    "model_names_default = [\n",
    "\t\"resnet18\",\n",
    "\t\"resnet34\",\n",
    "\t\"resnet50\",\n",
    "\t\"resnet101\",\n",
    "\t\"resnet152\", # doesn't fit in my machine's gpu\n",
    "\t\"vit_base_patch32_224\",\n",
    "\t\"vit_base_patch16_224\", # doesn't fit in my machine's gpu\n",
    "]\n",
    "\n",
    "# Smaller list for quick debugging\n",
    "model_names_debug = [\n",
    "\t\"resnet18\",\n",
    "\t\"resnet34\",\n",
    "\t\"vit_base_patch32_224\",\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c9a4ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n",
      "Sequential(\n",
      "  (0): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (1): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (2): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (3): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (4): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (5): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (6): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (7): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (8): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (9): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (10): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      "  (11): Block(\n",
      "    (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (attn): Attention(\n",
      "      (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "      (q_norm): Identity()\n",
      "      (k_norm): Identity()\n",
      "      (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls1): Identity()\n",
      "    (drop_path1): Identity()\n",
      "    (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (mlp): Mlp(\n",
      "      (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "      (act): GELU(approximate='none')\n",
      "      (drop1): Dropout(p=0.0, inplace=False)\n",
      "      (norm): Identity()\n",
      "      (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "      (drop2): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (ls2): Identity()\n",
      "    (drop_path2): Identity()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ViT\n",
    "model = create_model_with_timeout(\"vit_base_patch32_224\", 102, device = device)\n",
    "\n",
    "print(model.blocks)\n",
    "# for name, module in model.named_modules():\n",
    "#     print(name, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "296a01a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Linear(in_features=512, out_features=102, bias=True)\n",
      ")\n",
      "conv1 Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "act1 ReLU(inplace=True)\n",
      "maxpool MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "layer1 Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop_block): Identity()\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (aa): Identity()\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act2): ReLU(inplace=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop_block): Identity()\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (aa): Identity()\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act2): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "layer1.0 BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop_block): Identity()\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (aa): Identity()\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      ")\n",
      "layer1.0.conv1 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.0.bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer1.0.drop_block Identity()\n",
      "layer1.0.act1 ReLU(inplace=True)\n",
      "layer1.0.aa Identity()\n",
      "layer1.0.conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.0.bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer1.0.act2 ReLU(inplace=True)\n",
      "layer1.1 BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop_block): Identity()\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (aa): Identity()\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      ")\n",
      "layer1.1.conv1 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.1.bn1 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer1.1.drop_block Identity()\n",
      "layer1.1.act1 ReLU(inplace=True)\n",
      "layer1.1.aa Identity()\n",
      "layer1.1.conv2 Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer1.1.bn2 BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer1.1.act2 ReLU(inplace=True)\n",
      "layer2 Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop_block): Identity()\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (aa): Identity()\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act2): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop_block): Identity()\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (aa): Identity()\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act2): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "layer2.0 BasicBlock(\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop_block): Identity()\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (aa): Identity()\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer2.0.conv1 Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "layer2.0.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.0.drop_block Identity()\n",
      "layer2.0.act1 ReLU(inplace=True)\n",
      "layer2.0.aa Identity()\n",
      "layer2.0.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer2.0.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.0.act2 ReLU(inplace=True)\n",
      "layer2.0.downsample Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer2.0.downsample.0 Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "layer2.0.downsample.1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.1 BasicBlock(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop_block): Identity()\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (aa): Identity()\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      ")\n",
      "layer2.1.conv1 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer2.1.bn1 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.1.drop_block Identity()\n",
      "layer2.1.act1 ReLU(inplace=True)\n",
      "layer2.1.aa Identity()\n",
      "layer2.1.conv2 Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer2.1.bn2 BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer2.1.act2 ReLU(inplace=True)\n",
      "layer3 Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop_block): Identity()\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (aa): Identity()\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act2): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop_block): Identity()\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (aa): Identity()\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act2): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "layer3.0 BasicBlock(\n",
      "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop_block): Identity()\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (aa): Identity()\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer3.0.conv1 Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "layer3.0.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.0.drop_block Identity()\n",
      "layer3.0.act1 ReLU(inplace=True)\n",
      "layer3.0.aa Identity()\n",
      "layer3.0.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer3.0.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.0.act2 ReLU(inplace=True)\n",
      "layer3.0.downsample Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer3.0.downsample.0 Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "layer3.0.downsample.1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.1 BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop_block): Identity()\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (aa): Identity()\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      ")\n",
      "layer3.1.conv1 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer3.1.bn1 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.1.drop_block Identity()\n",
      "layer3.1.act1 ReLU(inplace=True)\n",
      "layer3.1.aa Identity()\n",
      "layer3.1.conv2 Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer3.1.bn2 BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer3.1.act2 ReLU(inplace=True)\n",
      "layer4 Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop_block): Identity()\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (aa): Identity()\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act2): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (drop_block): Identity()\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (aa): Identity()\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act2): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "layer4.0 BasicBlock(\n",
      "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop_block): Identity()\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (aa): Identity()\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "layer4.0.conv1 Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "layer4.0.bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.0.drop_block Identity()\n",
      "layer4.0.act1 ReLU(inplace=True)\n",
      "layer4.0.aa Identity()\n",
      "layer4.0.conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer4.0.bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.0.act2 ReLU(inplace=True)\n",
      "layer4.0.downsample Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "layer4.0.downsample.0 Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "layer4.0.downsample.1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.1 BasicBlock(\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop_block): Identity()\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (aa): Identity()\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act2): ReLU(inplace=True)\n",
      ")\n",
      "layer4.1.conv1 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer4.1.bn1 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.1.drop_block Identity()\n",
      "layer4.1.act1 ReLU(inplace=True)\n",
      "layer4.1.aa Identity()\n",
      "layer4.1.conv2 Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "layer4.1.bn2 BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "layer4.1.act2 ReLU(inplace=True)\n",
      "global_pool SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "global_pool.pool AdaptiveAvgPool2d(output_size=1)\n",
      "global_pool.flatten Flatten(start_dim=1, end_dim=-1)\n",
      "fc Linear(in_features=512, out_features=102, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Resnet\n",
    "model = create_model_with_timeout(\"resnet18\", 102, device = device)\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    print(name, module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyterVenv15Oct2024)",
   "language": "python",
   "name": "jupytervenv15oct2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
